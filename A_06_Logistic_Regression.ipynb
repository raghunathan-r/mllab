{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.489163</td>\n",
       "      <td>48.380286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42.261701</td>\n",
       "      <td>87.103851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99.315009</td>\n",
       "      <td>68.775409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>55.340018</td>\n",
       "      <td>64.931938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>74.775893</td>\n",
       "      <td>89.529813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1         x2  result\n",
       "0   34.623660  78.024693       0\n",
       "1   30.286711  43.894998       0\n",
       "2   35.847409  72.902198       0\n",
       "3   60.182599  86.308552       1\n",
       "4   79.032736  75.344376       1\n",
       "..        ...        ...     ...\n",
       "95  83.489163  48.380286       1\n",
       "96  42.261701  87.103851       1\n",
       "97  99.315009  68.775409       1\n",
       "98  55.340018  64.931938       1\n",
       "99  74.775893  89.529813       1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['x1', 'x2', 'result']\n",
    "\n",
    "df = pd.read_csv(\"./Logistic_Regression_Dataset_Students.csv\", header=None, names=col_names)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iloc indexer is used to extract a subset of the rows and columns from the dataset. The syntax is df.iloc[row_indexer, column_indexer], where df is the data frame, row_indexer is a list of row indices, and column_indexer is a list of column indices.\n",
    "\n",
    "In this case, ds.iloc[:, [0, 1]] selects all rows (:) and the first two columns (0 and 1). The resulting data frame is then converted to a NumPy array using the values attribute.\n",
    "\n",
    "So, x is a NumPy array containing the values in the first two columns of the dataset. These values correspond to the input features (x1 and x2) of the logistic regression model.\n",
    "\n",
    "```\n",
    "# input\n",
    "x = ds.iloc[:, [0, 1]].values\n",
    "```\n",
    "\n",
    "But we wont be using this in our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.62365962, 78.02469282],\n",
       "       [30.28671077, 43.89499752],\n",
       "       [35.84740877, 72.90219803],\n",
       "       [60.18259939, 86.3085521 ],\n",
       "       [79.03273605, 75.34437644],\n",
       "       [45.08327748, 56.31637178],\n",
       "       [61.10666454, 96.51142588],\n",
       "       [75.02474557, 46.55401354],\n",
       "       [76.0987867 , 87.42056972],\n",
       "       [84.43281996, 43.53339331],\n",
       "       [95.86155507, 38.22527806],\n",
       "       [75.01365839, 30.60326323],\n",
       "       [82.30705337, 76.4819633 ],\n",
       "       [69.36458876, 97.71869196],\n",
       "       [39.53833914, 76.03681085],\n",
       "       [53.97105215, 89.20735014],\n",
       "       [69.07014406, 52.74046973],\n",
       "       [67.94685548, 46.67857411],\n",
       "       [70.66150955, 92.92713789],\n",
       "       [76.97878373, 47.57596365],\n",
       "       [67.37202755, 42.83843832],\n",
       "       [89.67677575, 65.79936593],\n",
       "       [50.53478829, 48.85581153],\n",
       "       [34.21206098, 44.2095286 ],\n",
       "       [77.92409145, 68.97235999],\n",
       "       [62.27101367, 69.95445795],\n",
       "       [80.19018075, 44.82162893],\n",
       "       [93.1143888 , 38.80067034],\n",
       "       [61.83020602, 50.25610789],\n",
       "       [38.7858038 , 64.99568096],\n",
       "       [61.37928945, 72.80788731],\n",
       "       [85.40451939, 57.05198398],\n",
       "       [52.10797973, 63.12762377],\n",
       "       [52.04540477, 69.43286012],\n",
       "       [40.23689374, 71.16774802],\n",
       "       [54.63510555, 52.21388588],\n",
       "       [33.91550011, 98.86943574],\n",
       "       [64.17698887, 80.90806059],\n",
       "       [74.78925296, 41.57341523],\n",
       "       [34.18364003, 75.23772034],\n",
       "       [83.90239366, 56.30804622],\n",
       "       [51.54772027, 46.85629026],\n",
       "       [94.44336777, 65.56892161],\n",
       "       [82.36875376, 40.61825516],\n",
       "       [51.04775177, 45.82270146],\n",
       "       [62.22267576, 52.06099195],\n",
       "       [77.19303493, 70.4582    ],\n",
       "       [97.77159928, 86.72782233],\n",
       "       [62.0730638 , 96.76882412],\n",
       "       [91.5649745 , 88.69629255],\n",
       "       [79.94481794, 74.16311935],\n",
       "       [99.27252693, 60.999031  ],\n",
       "       [90.54671411, 43.39060181],\n",
       "       [34.52451385, 60.39634246],\n",
       "       [50.28649612, 49.80453881],\n",
       "       [49.58667722, 59.80895099],\n",
       "       [97.64563396, 68.86157272],\n",
       "       [32.57720017, 95.59854761],\n",
       "       [74.24869137, 69.82457123],\n",
       "       [71.79646206, 78.45356225],\n",
       "       [75.39561147, 85.75993667],\n",
       "       [35.28611282, 47.02051395],\n",
       "       [56.2538175 , 39.26147251],\n",
       "       [30.05882245, 49.59297387],\n",
       "       [44.66826172, 66.45008615],\n",
       "       [66.56089447, 41.09209808],\n",
       "       [40.45755098, 97.53518549],\n",
       "       [49.07256322, 51.88321182],\n",
       "       [80.27957401, 92.11606081],\n",
       "       [66.74671857, 60.99139403],\n",
       "       [32.72283304, 43.30717306],\n",
       "       [64.03932042, 78.03168802],\n",
       "       [72.34649423, 96.22759297],\n",
       "       [60.45788574, 73.0949981 ],\n",
       "       [58.84095622, 75.85844831],\n",
       "       [99.8278578 , 72.36925193],\n",
       "       [47.26426911, 88.475865  ],\n",
       "       [50.4581598 , 75.80985953],\n",
       "       [60.45555629, 42.50840944],\n",
       "       [82.22666158, 42.71987854],\n",
       "       [88.91389642, 69.8037889 ],\n",
       "       [94.83450672, 45.6943068 ],\n",
       "       [67.31925747, 66.58935318],\n",
       "       [57.23870632, 59.51428198],\n",
       "       [80.366756  , 90.9601479 ],\n",
       "       [68.46852179, 85.5943071 ],\n",
       "       [42.07545454, 78.844786  ],\n",
       "       [75.47770201, 90.424539  ],\n",
       "       [78.63542435, 96.64742717],\n",
       "       [52.34800399, 60.76950526],\n",
       "       [94.09433113, 77.15910509],\n",
       "       [90.44855097, 87.50879176],\n",
       "       [55.48216114, 35.57070347],\n",
       "       [74.49269242, 84.84513685],\n",
       "       [89.84580671, 45.35828361],\n",
       "       [83.48916274, 48.3802858 ],\n",
       "       [42.26170081, 87.10385094],\n",
       "       [99.31500881, 68.77540947],\n",
       "       [55.34001756, 64.93193801],\n",
       "       [74.775893  , 89.5298129 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the input features from the data frame and convert them to a NumPy array\n",
    "x = df[['x1', 'x2']].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the output labels from the data frame and convert them to a NumPy array\n",
    "y = df['result'].values\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale function from scikit-learn's preprocessing module standardizes the input features by scaling them so that they have zero mean and unit variance. Standardization can be useful for algorithms that assume that the input features have zero mean and unit variance, or when we want to compare the importance of different features.\n",
    "\n",
    "The scale function takes a NumPy array of shape (n_samples, n_features) as input and returns a standardized version of the input array.\n",
    "\n",
    "In this case, xp is a NumPy array containing the standardized versions of the input features (x1 and x2). Standardization is performed by subtracting the mean of each feature from each value and dividing by the standard deviation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the input features so they have zero mean and variance\n",
    "from sklearn import preprocessing\n",
    "xp = preprocessing.scale(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is training the logistic regression model using the training data and the stochastic gradient descent optimization algorithm.\n",
    "\n",
    "The KFold function from scikit-learn's model_selection module is used to split the data into folds for cross-validation. The n_splits argument specifies the number of folds to use. In this case, the data is split into 5 folds.\n",
    "\n",
    "The split method of KFold returns the indices of the training and test samples for each fold. The for loop iterates over the folds and uses the indices to extract the training and test samples from the input data (xp) and the labels (y).\n",
    "\n",
    "The training and test samples are then used to train and test the logistic regression model using the stochastic gradient descent algorithm. The model's weights (b0, b1, and b2) are updated at each epoch until the number of epochs (iterations) is exhausted. The alpha parameter is the learning rate, which controls the size of the weight updates.\n",
    "\n",
    "Finally, the trained model's weights (b0, b1, and b2) are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.274620542034513\n",
      "2.785686835762315\n",
      "3.0555177592607037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "# training the logistic regression model using the training data and the stochastic gradient descent optimization algorithm\n",
    "# we split the data into 5 folds using kfold so we cross verify\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# training and testing the logistic regression model using the stochastic gradient descent algorithm. model's weights (b0, b1, and b2) are updated at each epoch until the number of epochs (iterations) is exhausted. The alpha parameter is the learning rate, which controls the size of the weight update\n",
    "for train_index, test_index in kf.split(xp):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(xp, y, test_size = 0.20, random_state=0)\n",
    "    x1 = xtrain[:, 0]\n",
    "    x2 = xtrain[:, 1]\n",
    "    b0 = 0.0\n",
    "    b1 = 0.0\n",
    "    b2 = 0.0\n",
    "    epoch=1000\n",
    "    alpha=0.001\n",
    "    while(epoch > 0):\n",
    "        for i in range(len(xtrain)):\n",
    "            prediction = 1/(1 + np.exp(-b0 + b1*x1[i] + b2*x2[i]))\n",
    "            b0 = b0 + alpha*(ytrain[i] - prediction) * prediction * ( 1 - prediction) * 1.0\n",
    "            b1 = b1 + alpha*(ytrain[i] - prediction) * prediction * ( 1 - prediction) * x1[i]\n",
    "            b2 = b2 + alpha*(ytrain[i] - prediction) * prediction * ( 1 - prediction) * x2[i]\n",
    "        epoch = epoch - 1\n",
    "\n",
    "print(b0)\n",
    "print(b1)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# using the trained model to make predictions on the test set\n",
    "final_predictions = []\n",
    "\n",
    "x3 = xtest[:, 0]\n",
    "x4 = xtest[:, 1]\n",
    "\n",
    "print(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 15.0, 1.0, 25.0, 71.0, 12.0, 1.0, 2.0, 1.0, 17.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = [0] * len(xtest)\n",
    "\n",
    "for i in range(len(xtest)):\n",
    "    y_pred[i] = np.round( 1 / 1 + np.exp(-(b0 + b1*x3[i] + b2*x4[i])))\n",
    "    final_predictions.append(np.ceil(y_pred[i]))\n",
    "\n",
    "print(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy : \",accuracy_score(ytest,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "467a397cf1c5f9b4668be4aaa2bda14a83c8bfb801899d630e5c827963d9ea74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
